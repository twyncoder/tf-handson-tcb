{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDVqhA0svL_G"
      },
      "source": [
        "<table align=\"left\">\n",
        "  <td>\n",
        "    <a href=\"https://colab.research.google.com/github/twyncoder/tf-handson-tcb/blob/main/L04_IntroCNN_clasificacionMulticlase.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaCUJbO9vL_G"
      },
      "source": [
        "# Redes de Aprendizaje Profundo básicas con Keras y Tensorflow.\n",
        "## *Convolutional Deep Neural Networks (CNN) para clasificación multi-clase*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGNcfDfWvL_H"
      },
      "source": [
        "# 0. Preparación del entorno y comprobación de requisitos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-VFtI9zQvL_H"
      },
      "outputs": [],
      "source": [
        "# Common imports\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Confusion matrix\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# To plot pretty figures\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n",
        "\n",
        "# Where to save the figures\n",
        "PROJECT_ROOT_DIR = \".\"\n",
        "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\")\n",
        "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
        "\n",
        "def save_fig(fig_name, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
        "    path = os.path.join(IMAGES_PATH, fig_name + \".\" + fig_extension)\n",
        "    print(\"Saving figure\", fig_name)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
        "\n",
        "def print_history(history,title=None, extension='png'):\n",
        "    pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
        "    plt.grid(True)\n",
        "    #plt.gca().set_ylim(0, 1)\n",
        "    plt.xlabel(\"epochs\")\n",
        "    if(title!=None):\n",
        "        plt.title(title)\n",
        "        save_fig(title,fig_extension=extension)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6freOgeYvL_H"
      },
      "source": [
        "### Información de versiones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6NBAdx4wvL_H",
        "outputId": "4136b730-5f54-48d8-fac3-b23c796a153e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.17.1\n"
          ]
        }
      ],
      "source": [
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6Rv5J9gvL_H"
      },
      "source": [
        "### Comprobar si disponemos de una GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JIZAFc-dvL_I",
        "outputId": "65d48f86-0d85-4e64-d43a-7bee84aff0cd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.config.list_physical_devices('GPU')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XunZFZx-vL_I"
      },
      "source": [
        "# 1. Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4aCr549RvL_I"
      },
      "outputs": [],
      "source": [
        "from numpy import load\n",
        "data = load('bloodmnist.npz')\n",
        "X_train_orig = data['train_images']\n",
        "X_valid_orig = data['val_images']\n",
        "X_test_orig = data['test_images']\n",
        "Y_train = data['train_labels']\n",
        "Y_valid = data['val_labels']\n",
        "Y_test = data['test_labels']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BffImmkIvL_I"
      },
      "source": [
        "A continuación se dispone de las etiquetas de las clases a las que pueden pertenecer las imágenes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "bgrya0VTvL_I"
      },
      "outputs": [],
      "source": [
        "labels = [\"basophil\",\"eosinophil\",\"erythroblast\",\"immature granulocytes\",\n",
        "          \"lymphocyte\",\"monocyte\",\"neutrophil\",\"platelet\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lC5P7gngvL_I"
      },
      "source": [
        "**¡AHORA TÚ!**\n",
        "- Averigua las dimensiones de los datos de entrada proporcionados en el dataset\n",
        "- Escribe una función para mostrar ejemplos de la base de datos con su etiqueta correspondiente y llámala desde la celda de más abajo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Q_9c5ou2vL_I"
      },
      "outputs": [],
      "source": [
        "#TODO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def show_example(x,y):\n",
        "    #<<<FIXME>>>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "RzW2FlqsvL_I",
        "outputId": "b2f78188-de4f-4687-e642-e065d83d1532"
      },
      "outputs": [],
      "source": [
        "N = 5\n",
        "show_example(X_train_orig[N],Y_train[N])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJYlxp3svL_J"
      },
      "source": [
        "### Estandarización de las entradas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "A2107JusvL_J"
      },
      "outputs": [],
      "source": [
        "X_mean = X_train_orig.mean(axis=0, keepdims=True)\n",
        "X_std = X_train_orig.std(axis=0, keepdims=True) + 1e-7\n",
        "X_train = (X_train_orig - X_mean) / X_std\n",
        "X_valid = (X_valid_orig - X_mean) / X_std\n",
        "X_test = (X_test_orig - X_mean) / X_std"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zjVmex5vL_J"
      },
      "source": [
        "**¡AHORA TÚ!**\n",
        "- Observa las dimensiones de `X_mean` y `X_std` con `.shape` y explica cómo se está haciendo la estandarización de los datos de entrada a la red.\n",
        "- Observa que `X_mean` y `X_std` se calculan sobre el set de entrenamiento, pero después se aplican también para **pseudo estandarizar** el set de validación y el set de test, ¿puedes explicar por qué no se calculan `X_mean` y `X_std` sobre todas las imágenes disponibles y solamente sobre el set de entrenamiento?."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "vDGLWr5zvL_J"
      },
      "outputs": [],
      "source": [
        "#TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5t0OPHX6vL_J"
      },
      "source": [
        "# 2. Entrenamiento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2mHC2-9vL_J"
      },
      "source": [
        "## Modelo 'base' de red neuronal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "wv3I0MKkvL_J",
        "outputId": "279c0abf-41d8-4eac-c68d-4c0340826b3a"
      },
      "outputs": [],
      "source": [
        "model1 = keras.models.Sequential()\n",
        "model1.add(keras.layers.Conv2D(16, kernel_size=(3, 3),\n",
        "                 activation='relu', padding='same',\n",
        "                 input_shape=(28, 28, 3)))\n",
        "model1.add(keras.layers.MaxPooling2D((2, 2)))\n",
        "model1.add(keras.layers.Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',  padding='same'))\n",
        "model1.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model1.add(keras.layers.Flatten())\n",
        "model1.add(keras.layers.Dense(32, activation='relu'))\n",
        "model1.add(keras.layers.Dense(<<<FIXME>>>, activation='softmax'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEcU5F4HvL_J"
      },
      "source": [
        "**¡AHORA TÚ!**\n",
        "- En base a la anterior definición de red neuronal:\n",
        "  - Añade el valor adecuado en <<<FIXME>>>\n",
        "  - Busca información sobre `keras.layers.Conv2D()` y averigua qué quiere decir `padding='same'`. ¿Qué otra opción existe para este parámetro y qué implicaciones tiene usarla?\n",
        "  - ¿Cuántos _feature maps_ o `channels` se generan a la salida de la primera capa? ¿de qué tamaño son los `kernels` de convolución?\n",
        "  - ¿Eres capaz de intuir cuáles serán las dimensiones de los _feature maps_ después de realizar el primer _pooling_?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4O2gkjKCvL_J"
      },
      "source": [
        "**¡AHORA TÚ!**\n",
        "- Obtén un `summary()` de la red anterior responde a las siguientes cuestiones:\n",
        "   - Asegúrate de entender cómo disminuye el tamaño de las capas en `height` y `width` desde 28x28 px a la entrada hasta 7x7 después de la última capa de _pooling_.\n",
        "   - ¿Cuántos parámetros entrenables tiene la red? Compara esta cifra con el número de parámetros de los modelos _fully connected_ de cuadernos anteriores. ¡Estamos creando una red con menos parámetros y esperamos que se comporte mejor!\n",
        "   - ¿Eres capaz de explicar el número de parámetros entrenables de alguna de las capas?\n",
        "   - Puedes probar a cambiar la configuración de `model1` y ver cómo afecta a los tamaños y número de capas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "4S-vzEScvL_K"
      },
      "outputs": [],
      "source": [
        "#TODO SUMMARY"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cIY5r-tvL_K"
      },
      "source": [
        "**¡AHORA TÚ!**\n",
        "- Entrena la red neuronal durante 15 epochs con un optimizador `adam`\n",
        "- Ve observando durante el entrenamiento los resultados de `acc` y `val_acc`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "BzkDIy5_vL_K"
      },
      "outputs": [],
      "source": [
        "#TODO COMPILE MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#TODO FIT MODEL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6DZwrJyvL_K"
      },
      "source": [
        "**¡AHORA TÚ!**\n",
        "- Muestra una gráfica la evolución del entrenamiento\n",
        "  - ¿Se produce _overfitting_ durante el entrenamiento? Si es así, ¿a partir de qué _epoch_ aproximadamente?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#TODO PLOT HISTORY"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yc7l0U1yvL_K"
      },
      "source": [
        "## Batch Normalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RbBeVTJvL_K"
      },
      "source": [
        "Vamos a incorporar capas de `BatchNormalization()` a nuestro modelo.\n",
        "- Llámalo esta vez `model2`\n",
        "- Batch Normalization actúa como técnica de regularización.\n",
        "- Prueba a introducirlo entre las capas de convolución y _pooling_ y en la penúltima capa _fully connected_\n",
        "- **No** debes incluir las activaciones en la capa anterior a `BatchNormalization()` **pero debes** incluir una capa de activación en la capa siguiente.\n",
        "- ¿Cuántos parámetros entrenables y no entrenables se han añadido a la red?\n",
        "- **No entrenes la red todavía**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "3G5TmFg6vL_K"
      },
      "outputs": [],
      "source": [
        "#TODO BATCHNORMALIZATION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tnv6OY29vL_L"
      },
      "source": [
        "## Early Stopping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljRABQpKvL_L"
      },
      "source": [
        "- Parar el entrenamiento es una forma de prevenir que la red sobreentrene y también de no gastar tiempo de cómputo innecesariamente.\n",
        "- Se puede dejar a la red que siga entrenando durante un tiempo, pero utilizar después en la etapa de inferencia los parámetros que proporcionaron el menor `val_loss` o la mejor `val_acc` (distintos de los de la última _epoch_)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "hnn3IL3VvL_L"
      },
      "outputs": [],
      "source": [
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=3,verbose=1)\n",
        "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"model2.keras\", save_best_only=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MPqxe-WvL_L"
      },
      "source": [
        "**¡AHORA TÚ!**\n",
        "- Vamos a entrenar la red `model2` durante 15 _epochs_ y a guardar los resultados del entrenamiento en una variable `history2`\n",
        "- Para el entrenamiento, incluye los _callbacks_ `early_stopping_cb` y `model_checkpoint_cb` tal y como los hemos definido arriba. Para ejecutar varios _callback_ simultáneamente recuerda que puedes hacer una lista con corchetes en la llamada en la función `fit()`.\n",
        "- Mientras se realiza el entrenamiento revisa información sobre `EarlyStopping()` y `ModelCheckpoint()`.\n",
        "   - https://keras.io/api/callbacks/early_stopping/\n",
        "   - https://keras.io/api/callbacks/model_checkpoint/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "nvdrx-qavL_L"
      },
      "outputs": [],
      "source": [
        "#TODO EARLY STOPPING"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vD-l6p0vL_L"
      },
      "source": [
        "**¡AHORA TÚ!**\n",
        "- Finalizado el entrenamiento, representa un gráfico con la evolución de la red y a continuación, responde a las siguientes preguntas:\n",
        "  - ¿En qué _epoch_ se ha parado el entrenamiento?\n",
        "  - ¿En qué _epoch_ se obtenía el menor _val_loss_?\n",
        "  - ¿Los parámetros de qué epoch se han salvado en 'model2.keras'?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "IcKd0p9AvL_L"
      },
      "outputs": [],
      "source": [
        "#TODO PLOT HISTORY"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Db_ePaNVvL_L"
      },
      "source": [
        "## Variación dinámica del learning rate\n",
        "- Una forma de prevenir el sobreentrenamiento es ir disminuyendo de manera dinámica el _learning rate_. De hecho, algunos optimizadores lo hacen internamente de manera automática.\n",
        "- Entre las estrategias más utilizadas encontramos _Reduce on plateau_, que consiste en añadir un _callback_ para que se reduzca el `learning_rate` cuando el _loss_ se queda en una meseta."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "-f0KJYaBvL_L"
      },
      "outputs": [],
      "source": [
        "lr_scheduler = keras.callbacks.ReduceLROnPlateau(monitor='val_loss',factor=0.4, patience=2,verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-FDWHR9vL_L"
      },
      "source": [
        "**¡AHORA TÚ!**\n",
        "- Vamos a volver a entrenar modelo `model1` (sin _Batch Normalization_) o `model2`, pero esta vez variando el _learning rate_ dinámicamente.\n",
        "- Vuelve a definir el modelo y llámalo `model3`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "wuyvaenZvL_L"
      },
      "outputs": [],
      "source": [
        "#TODO NEW MODEL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WasUPBddvL_L"
      },
      "source": [
        "**¡AHORA TÚ!**\n",
        "- Añade el _callback_ `lr_scheduler` durante el entrenamiento, junto con  `model_checkpoint_cb`.\n",
        "- Opcionalmente puedes añadir el callback `early_stopping_cb`, pero si el entrenamiento para demasido pronto y no se disminuye el _learning_rate_ y quieras quitarlo para poder observar bien el efecto de `lr_scheduler`.\n",
        "- Para no sobreescribir `model2.h5` será mejor que vuelvas a definir `model_checkpoint_cb` e incluir esta vez `model3.keras`.\n",
        "- Lanza un entrenamiento con al menos 20 epochs y empleando el siguiente optimizador\n",
        "- Mientras se realiza revisa información sobre `EarlyStopping()`.\n",
        "   - https://keras.io/api/callbacks/reduce_lr_on_plateau/\n",
        "- Grafica los resultados y compara con entrenamientos anteriores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "lU28nSgDvL_L"
      },
      "outputs": [],
      "source": [
        "optimizer = keras.optimizers.Adam(learning_rate=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "esMTMOoVvL_L"
      },
      "outputs": [],
      "source": [
        "#TODO DEFINE CALLBACK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#TODO COMPILE MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#TODO FIT MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#TODO PLOT HISTORY"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wo2U4V2IvL_M"
      },
      "source": [
        "## Dropout\n",
        "- Puedes introducir capas de Dropout de la siguiente manera.\n",
        "\n",
        "`keras.layers.Dropout(rate=...)`\n",
        "\n",
        "**¡AHORA TÚ!**\n",
        "- Crea un nuevo modelo `model4` añadiendo capas de dropout  después de las capas de _pooling_ en `model2`. Puedes probar con valores de `rate=0.25` por ejemplo.\n",
        "- Lanza un entrenamiento de al menos 20 _epochs_ y con _Early Stopping_ y que guarde los pesos en `model4.keras`. Utiliza un valor de `epochs` y `patience` acorde a las capacidades de procesamiento de tu ordenador. Si es lento no pongas valores elevados. El valor de `patience` en el callback que reduce el _learning_rate_ deberá ser mayor que en callback que hace el _model_checkpoint_.\n",
        "- Durante el mismo busca información sobre las capas `Dropout` y el parámetro `rate`.\n",
        "- Grafica nuevamente los resultados y compara el entrenamiento con los modelos anteriores\n",
        "- Por último, si el entrenamiento no se hubiera parado en la última _epoch_, salva los resultados con `model4.save(\"model4.keras\")`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0DmDesulvL_M"
      },
      "outputs": [],
      "source": [
        "#TODO DEFINE MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#TODO COMPILE MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#TODO CALLBACKS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#TODO FIT MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#TODO PLOT HISTORY"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibsNoYewvL_M"
      },
      "source": [
        "## 3. Test\n",
        "**¡AHORA TÚ!**\n",
        "- Carga alguno de los modelos salvados anteriormente y evalúalo (usando `evaluate()`), sobre las muestras reservadas para test.\n",
        "- A continuación:\n",
        "  - Evalúa el modelo sobre el set de test empleando `evaluate()`\n",
        "  - En otra celda genera predicciones con `predict()` sobre **todo el subconjunto de test**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "eAbVjUL7vL_M"
      },
      "outputs": [],
      "source": [
        "#TODO LOAD MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#TODO EVALUATE MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#TODO PREDICT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUg667vkvL_M"
      },
      "source": [
        "### Matriz de confusión\n",
        "**¡AHORA TÚ!**\n",
        "- Utiliza las predicciones anteriores para generar un matriz de confusión normalizada y otra sin normalizar.\n",
        "    - https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HbQzpB2vL_N"
      },
      "source": [
        "### Métricas de rendimiento\n",
        "**¡AHORA TÚ!**\n",
        "- Genera ahora una matriz de confusión sin normalizar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_efgKGIyvL_N"
      },
      "outputs": [],
      "source": [
        "#TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6Iv7ApJvL_N"
      },
      "source": [
        "**¡AHORA TÚ!**\n",
        "- Observa cómo podemos obtener los TP,TN,FP y FN a partir de la matriz de confusión `conf`.\n",
        "- Revisa el significado de estas variables y entiende cómo se han obtenido a partir de `conf`. ¿Por qué estas variables se expresan en forma de vectores en lugar de valores escalares?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "UQm84oWHvL_N"
      },
      "outputs": [],
      "source": [
        "TP = np.diag(conf)\n",
        "FP = conf.sum(axis=0) - TP\n",
        "FN = conf.sum(axis=1) - TP\n",
        "TN = conf.sum() - (FP + FN + TP)\n",
        "FP = FP.astype(float)\n",
        "FN = FN.astype(float)\n",
        "TP = TP.astype(float)\n",
        "TN = TN.astype(float)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eC3-7d3pvL_N"
      },
      "source": [
        "**¡AHORA TÚ!**\n",
        "- Calcula e imprime la métrica F1-score para cada clase y su valor medio.\n",
        "- ¿Cuáles son las clases con las mejores/peores métricas F1-score?\n",
        "- Prueba a calcular e imprimir también las métricas _Accuracy_, _Sensitivity_ y _Specificity_."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywr_ZtGGvL_N"
      },
      "source": [
        "# 4. Mejorando el modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DnDeQsDVvL_N"
      },
      "source": [
        "### L1 and L2 Regularization\n",
        "- Podemos incluir regularización L2 con factor 0.01 en las capas Dense o Conv2D de la siguiente manera:\n",
        "```\n",
        "keras.layers.Dense(100, activation= ...,                                  \n",
        "                    kernel_regularizer=keras.regularizers.l2(0.01))\n",
        "keras.layers.Conv2D(32, kernel_size=...,kernel_regularizer=keras.regularizers.l2(0.01),...)\n",
        " - `l2(0.01)` para L2 con factor 0.01\n",
        " - `l1(0.1)` para L1 con factor 0.1\n",
        " - `l1_l2(0.1, 0.01)` para L1 y L2 con factores 0.1 y 0.01 respectivamente\n",
        "```\n",
        "\n",
        "**¡AHORA TÚ!**\n",
        "- Crea un nuevo modelo `model5` probando a introducir regularización en las distintas capas de `model3` y entrena durante al menos 25 épocas utilizando _Early Stopping_ y algún otro _callback_ de tu elección."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#TODO..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icXNq5HPvL_N"
      },
      "source": [
        "### (Opcional) Aumentando la profundidad de la red"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQo7Hi4gvL_N"
      },
      "source": [
        "**¡AHORA TÚ!**\n",
        "- Para hacer este apartado se requiere utilizar la nube de cómputo o un ordenador potente configurados con GPUs\n",
        "- Lo que tenemos hasta ahora no es una red suficientemente _\"deep\"_. Crea un modelo `model6` aumentando el número de capas convolucionales de la red `model4` y la profundidad de la red (número de filtros de convolución).   \n",
        "  - Deberías aumentar el número de channels en las capas más profundas de la red, ¿sabes contestar por qué?.\n",
        "   - Observa que también puedes aumentar el número de neuronas en la capa _hidden_ de perceptrón multicapa (MLP) que hay al final de la red.\n",
        "   - Controla el número de parámetros entrenables y número de capas en un tamaño manejable para el equipo que estás utilizando.\n",
        "   - No utilices regularización L2 en este experimento si tu ordenador es demasiado lento.\n",
        "   - Recuerda que puedes añadir _callbacks_ para variar el _learning rate_ dinámicamente.\n",
        "   - Lanza el entrenamiento para un número de _epochs_ elevado (por ejemplo 50) y recuerda que puedes utilizar _early stopping_ ajustando el parámetro _patience_.\n",
        "- A ver si puedes obtener un resultado cercano a `val_accuracy` en torno a 93%... ¡o mejor aún!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iakT_ux9vL_O"
      },
      "source": [
        "## Ampliación"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FqrExcqvL_O"
      },
      "source": [
        "- Blog towardsdatascience: The 4 Convolutional Neural Network Models That Can Classify Your Fashion Images\n",
        "\n",
        "https://towardsdatascience.com/the-4-convolutional-neural-network-models-that-can-classify-your-fashion-images-9fe7f3e5399d\n",
        "- Fashion MNIST benchmark\n",
        "\n",
        "https://paperswithcode.com/sota/image-classification-on-fashion-mnist"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "nav_menu": {},
    "toc": {
      "navigate_menu": true,
      "number_sections": true,
      "sideBar": true,
      "threshold": 6,
      "toc_cell": false,
      "toc_section_display": "block",
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
